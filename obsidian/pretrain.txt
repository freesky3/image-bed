import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset

from tqdm import tqdm
import os
import numpy as np

# --- 1. CONFIGURATION FOR PRE-TRAINING ---
CONFIG = {
    "real_t_path": "/userhome/fangzikai/wan_EEG2Video/data/text_embedding_t5_wan2.1-1.3B.pt", 
    'BATCH_SIZE': 4,
    'NUM_WORKERS': 12, 
    'lr': 1e-5,
    'num_epochs': 5000,
    'model_save_path': "/userhome/fangzikai/wan_EEG2Video/checkpoints/simple_input_pretrained_model.pth", 
}
DEVICE = "cuda:2" if torch.cuda.is_available() else "cpu"


# --- 2. PRE-TRAINING DATASET & DATALOADER (使用 Embedding 方案) ---
class PretrainEmbeddingDataset(Dataset):
    def __init__(self, gt_tensor):
        self.gt_tensor = gt_tensor
        self.num_samples = len(gt_tensor)
        print(f"Pretrain dataset initialized with {self.num_samples} samples.")

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        target_embedding = self.gt_tensor[idx, :88, :]
        # 输入现在是样本的整数索引
        return idx, target_embedding

def get_pretrain_dataloader():
    print("Loading ground truth text embeddings for pretraining...")
    gt_tensor = torch.load(CONFIG["real_t_path"])
    print(f"Ground truth tensor loaded with shape: {gt_tensor.shape}")

    full_dataset = PretrainEmbeddingDataset(gt_tensor)
    
    train_loader = DataLoader(full_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, drop_last=True, num_workers=CONFIG['NUM_WORKERS'], pin_memory=True)
    valid_loader = DataLoader(full_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=CONFIG['NUM_WORKERS'], pin_memory=True)
    
    print(f"Created {len(train_loader)} training and {len(valid_loader)} validation batches.")
    return train_loader, valid_loader, len(full_dataset)


# --- 3. MODEL (使用 Embedding 方案) ---
class ResidualBlock(nn.Module):
    def __init__(self, feature_dim, dropout=0.05):
        super().__init__()
        self.block = nn.Sequential(
            nn.Linear(feature_dim, feature_dim),
            nn.GELU(),
            nn.Linear(feature_dim, feature_dim),
            nn.GELU()
        )

    def forward(self, x):
        return x + self.block(x)

class EEGNetFC_v4_Embedding(nn.Module):
    def __init__(self, num_embeddings, embedding_dim=512, emb_dim=4096, 
                 output_seq_len=88, output_feat_dim=4096, dropout=0.05, num_res_blocks=2): # 你可以增加 num_res_blocks
        super().__init__()
        
        self.output_seq_len = output_seq_len
        self.output_feat_dim = output_feat_dim
        output_size = output_seq_len * output_feat_dim

        self.embedding_layer = nn.Embedding(num_embeddings, embedding_dim)
        self.input_layer = nn.Sequential(
            nn.Linear(embedding_dim, emb_dim),
            nn.GELU()
        )
        self.residual_blocks = nn.Sequential(
            *[ResidualBlock(emb_dim, dropout) for _ in range(num_res_blocks)]
        )
        self.output_layer = nn.Linear(emb_dim, output_size)
        
    def forward(self, src_idx):
        x = self.embedding_layer(src_idx)
        x = self.input_layer(x)
        x = self.residual_blocks(x)
        x = self.output_layer(x)
        output = x.view(-1, self.output_seq_len, self.output_feat_dim)
        return output

# --- 4. LOSS & TRAINING LOOPS ---
def combined_loss(pred, target, alpha=0.95):
    mse = F.mse_loss(pred, target)
    cosine = 1 - F.cosine_similarity(pred, target, dim=-1).mean()
    return alpha * mse + (1 - alpha) * cosine

def train_one_epoch(model, dataloader, optimizer, loss_fn, device, clip_value=1.0):
    model.train()
    total_loss = 0.0
    progress_bar = tqdm(dataloader, desc="Pre-Training", leave=False)
    for inputs, targets in progress_bar:
        # ############## FIX: 分别处理 inputs 和 targets 的数据类型 ##############
        inputs = inputs.to(device, dtype=torch.long)
        targets = targets.to(device, dtype=torch.float32)
        # ######################################################################
        optimizer.zero_grad()
        predictions = model(inputs)
        loss = loss_fn(predictions, targets)
        loss.backward()
        if clip_value:
            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)
        optimizer.step()
        total_loss += loss.item()
        progress_bar.set_postfix(loss=f"{loss.item():.4f}")
    return total_loss / len(dataloader)

def valid_one_epoch(model, dataloader, loss_fn, device):
    model.eval()
    total_loss = 0.0
    with torch.no_grad():
        progress_bar = tqdm(dataloader, desc="Validating", leave=False)
        for inputs, targets in progress_bar:
            # ############## FIX: 分别处理 inputs 和 targets 的数据类型 ##############
            inputs = inputs.to(device, dtype=torch.long)
            targets = targets.to(device, dtype=torch.float32)
            # ######################################################################
            predictions = model(inputs)
            loss = loss_fn(predictions, targets)
            total_loss += loss.item()
            progress_bar.set_postfix(loss=f"{loss.item():.4f}")
    return total_loss / len(dataloader)

# --- 5. MAIN PRE-TRAINING FUNCTION ---
def main_pretrain():
    print("--- Starting Pre-training Phase with Simple Inputs ---")
    print(f"Device: {DEVICE}\n")

    train_loader, valid_loader, num_samples = get_pretrain_dataloader()

    model = EEGNetFC_v4_Embedding(
        num_embeddings=num_samples,
        num_res_blocks=2, # 建议增加到 8 以便快速过拟合
        dropout=0.05
    ).to(DEVICE)
    print("\nModel Architecture:\n", model)
    
    loss_fn = combined_loss
    optimizer = optim.Adam(model.parameters(), lr=CONFIG['lr'])
    # 建议使用 CosineAnnealingLR 来强制过拟合
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500, eta_min=1e-7)

    best_valid_loss = float('inf')
    
    if os.path.exists(CONFIG['model_save_path']):
        print(f"\n--- Found existing model. Resuming pre-training from: {CONFIG['model_save_path']} ---")
        model.load_state_dict(torch.load(CONFIG['model_save_path'], map_location=DEVICE))
        best_valid_loss = valid_one_epoch(model, valid_loader, loss_fn, DEVICE)
        print(f"Resuming with baseline validation loss: {best_valid_loss:.6f}\n")
    else:
        print("\n--- No existing model found. Starting pre-training from scratch. ---\n")

    for epoch in range(CONFIG['num_epochs']):
        train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, DEVICE)
        valid_loss = valid_one_epoch(model, valid_loader, loss_fn, DEVICE)
        
        scheduler.step() # CosineAnnealingLR 不需要参数
        
        current_lr = optimizer.param_groups[0]['lr']
        print(f"Epoch {epoch+1}/{CONFIG['num_epochs']} | Train Loss: {train_loss:.6f} | Valid Loss: {valid_loss:.6f} | LR: {current_lr:.2e}")

        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            # torch.save(model.state_dict(), CONFIG['model_save_path']) # 你之前注释掉了，如果需要保存最佳模型请取消注释
            print(f"  -> New best pre-trained model saved! Validation loss: {best_valid_loss:.6f}")

        if (epoch + 1) % 20 == 0:
            savepath = CONFIG['model_save_path']
            torch.save(model.state_dict(), savepath)
            print(f"  -> Periodic checkpoint saved at epoch {epoch+1} to: {savepath}")

    print("\n--- Pre-training Finished ---")
    print(f"Best pre-trained model saved to: {CONFIG['model_save_path']} with validation loss {best_valid_loss:.6f}")

if __name__ == '__main__':
    main_pretrain()